# kickstarter

**Regression, Classification, and Clustering Analysis of Kickstarter Projects**

Kickstarter is an online crowdfunding platform which connects creators with seed-funding to support various projects and initiatives. Creators advertise their projects to attract backers and are only funded if the project reaches its goal within a launch period. This analysis aims to predict the outcome of a project at time of launch. I used regression to predict the amount of funds pledged (in USD), classification to predict if a project was successful (i.e., it reached the funding goal), and cluster analysis to explore factors associated with successful vs. unsuccessful projects. 

**Predictor Selection**: To select predictors for regression and classification, variables which could only be observed post-launch, highly correlated variables, identifier categorical variables, and predominantly single-class categorical variables were excluded. Variables with presumably low-predictive value (i.e., project deadline hour) were excluded based on logical intuition, and high-cardinality categorical variables were identified and encoded into more balanced classes based on domain-knowledge. To standardize goal amount across currencies, goal amount was multiplied by the conversion rate to USD. Two additional variables were derived – goal to launch period ratio, and the goal to project pre-launch period ratio – to contextualize goal with a time dimension.

**Regression**: The Gradient Boost (GB) Regressor achieved the lowest MSE score and was selected for regression. GB builds an ensemble of small, sequential trees, each correcting for the prediction error of the previous tree. Thus, it is unsurprising that GB outperformed all other models tested, since many simple trees control for the high variance of single tree methods. To further reduce the base MSE prediction of GB, predictors with marginal-to-no predictive value were removed using their feature importance ranking, and 2.5% of extreme outliers were removed via anomaly detection. Four hyperparameters were tuned using GridSearchCV: trees to be built, min. samples to split a node, min. samples in a terminal node, and the max. depth of a tree –as to control for overfitting. The MSE fluctuated greatly on different splits of the train/test data, thus a five-fold cross validation was performed to increase model robustness. 

**Classification**: After comparing performance across models, the Gradient Boost Classifier was likewise identified to have the highest predictive accuracy. Additional feature elimination did not improve prediction accuracy, and so was not performed. Other outlier removal, model tuning, and cross validation techniques described for regression were likewise repeated for classification. 

**Business Implications**: Based on a predictor’s contribution to decreasing node impurity when splitting the GB tree, predictors with most explanatory power for USD pledged were the campaign goal amount, the ratio of goal to launch days, name length (clean), and launch to deadline period, while the top predictors for project success status were goal amount (USD), ratio of goal to pre-launch period, and name length (clean). Web and software categories were also important features for classification, but it should be noted that importance rankings can be highly biased towards categorical variables. Given that the median pledge amount is 870 USD, the regression model performed poorly; it is unlikely that it could be used by Kickstarter to anticipate how much funding a project may generate based on a project’s inherent characteristics alone. Meanwhile, the classification model accurately classified 74% of total projects; specifically, 67% of all projects identified as successful were in fact successful (precision), and of all successful projects, 55% were identified as such (recall). A high precision/low recall prediction is ideal if Kickstarter wants to protect its reputation from frequent false claims of project success and remain conservative in classifying future projects as likely to succeed, though it may discourage new creators from launching projects. The success classification thus represents a low-cost, risk-adverse analysis that Kickstarter could feasibly use to provide insights to its creators, such as via a subscription-based report. To improve business insights, Kickstarter should segment predictions by category, since project success rates varied greatly between categories (i.e., 62% of plays were successful while only 8% of web projects were successful), and by year, since projects launched prior to 2014 faced lower competition (fewer total projects) and had much higher success rates. 

**Clustering Insights**: A K-Means model was created to cluster projects by three characteristics identified as important for prediction: launch to deadline days, goal (USD) and name length (clean). At four clusters, within-cluster variation (inertia) was ideally minimized, and the clusters achieved suitable within cluster cohesion and between cluster separation, with an average silhouette score of 0.379 and individual silhouette scores from 0.3-0.4. I found that Cluster 1 (C1) is comprised of projects with shorter names (< 50th percentile), while C3 contains longer names (>50th). C3 has ~50% more successful projects than C1; possibly, longer names contain more key word terms that could come up in searches and increase exposure for successful funding. Both C1 and C3 represent the majority of projects, and have predominantly shorter launch periods. C2 contains projects with launch periods from the 26-50th percentile that are largely unsuccessfully funded. C4 contains a minority of projects, but logically suggests that projects with large funding goals (>75th percentile) and short funding periods (majority <50th percentile) are also unlikely to be successfully funded. 




